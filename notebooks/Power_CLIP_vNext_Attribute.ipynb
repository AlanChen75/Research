{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âš¡ Power-CLIP vNext: Attribute-Level Zero-Shot\n",
                "\n",
                "**æ ¸å¿ƒè½‰å‘**: Power â†’ Attributes â†’ Device Reasoning\n",
                "\n",
                "> *\"We reformulate NILM zero-shot as an attribute grounding problem rather than direct class matching.\"*\n",
                "\n",
                "**æž¶æ§‹**:\n",
                "- 20 Attribute Prototypes (5 tiers)\n",
                "- Multi-positive Contrastive Loss\n",
                "- Rule-based Device Reasoning\n",
                "- LLM Explanation (post-hoc)\n",
                "\n",
                "**ç‰ˆæœ¬**: 2025-12-31 vNext"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ“‚ Setup\n",
                "from google.colab import drive, userdata\n",
                "import os, json, torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from tqdm.auto import tqdm\n",
                "import random\n",
                "\n",
                "drive.mount('/content/drive')\n",
                "BASE_PATH = '/content/drive/MyDrive/Reserach/REDD_Dataset'\n",
                "os.chdir(BASE_PATH)\n",
                "\n",
                "SEED = 42\n",
                "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'ðŸ”¥ Device: {DEVICE}')\n",
                "\n",
                "EPOCHS = 20\n",
                "LR = 1e-3\n",
                "BATCH_SIZE = 32\n",
                "TEMPERATURE = 0.07"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q sentence-transformers google-generativeai"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ“‹ Attribute Ontology (20 prototypes)\n",
                "\n",
                "ATTRIBUTES = {\n",
                "    # Power Shape (5)\n",
                "    'PS1': {'name': 'constant_high', 'text': 'sustained high power consumption above 500W'},\n",
                "    'PS2': {'name': 'constant_low', 'text': 'sustained low power consumption under 200W'},\n",
                "    'PS3': {'name': 'cyclic', 'text': 'power cycles on and off periodically'},\n",
                "    'PS4': {'name': 'burst', 'text': 'short bursts of high power'},\n",
                "    'PS5': {'name': 'fluctuating', 'text': 'continuously fluctuating power levels'},\n",
                "    # Temporal (4)\n",
                "    'T1': {'name': 'long_operation', 'text': 'operates continuously for 30+ minutes'},\n",
                "    'T2': {'name': 'short_usage', 'text': 'used for less than 10 minutes at a time'},\n",
                "    'T3': {'name': 'periodic_cycle', 'text': 'regular on-off cycles every 15-30 minutes'},\n",
                "    'T4': {'name': 'instantaneous', 'text': 'very brief operation under 5 minutes'},\n",
                "    # Load Type (5)\n",
                "    'L1': {'name': 'resistive', 'text': 'purely resistive heating load with stable power'},\n",
                "    'L2': {'name': 'inductive_motor', 'text': 'inductive motor load with startup surge'},\n",
                "    'L3': {'name': 'switching', 'text': 'switching power supply with high frequency noise'},\n",
                "    'L4': {'name': 'heating_element', 'text': 'resistive heating element with thermal cycling'},\n",
                "    'L5': {'name': 'compressor', 'text': 'compressor motor with periodic start-stop'},\n",
                "    # Power Level (4)\n",
                "    'P1': {'name': 'very_high', 'text': 'power consumption above 1500W'},\n",
                "    'P2': {'name': 'high', 'text': 'power consumption between 500W and 1500W'},\n",
                "    'P3': {'name': 'medium', 'text': 'power consumption between 100W and 500W'},\n",
                "    'P4': {'name': 'low', 'text': 'power consumption below 100W'},\n",
                "    # Stability (2)\n",
                "    'S1': {'name': 'stable', 'text': 'very stable and consistent power draw'},\n",
                "    'S2': {'name': 'variable', 'text': 'highly variable and unpredictable power'},\n",
                "}\n",
                "\n",
                "ATTR_IDS = list(ATTRIBUTES.keys())\n",
                "ATTR_TEXTS = [ATTRIBUTES[k]['text'] for k in ATTR_IDS]\n",
                "\n",
                "# Device â†’ Attribute Mapping\n",
                "DEVICE_ATTRS = {\n",
                "    'fridge': ['L5', 'T3', 'P4', 'PS3', 'S1'],\n",
                "    'microwave': ['L1', 'T4', 'P1', 'PS4', 'S1'],\n",
                "    'dish washer': ['L2', 'L4', 'T1', 'P2', 'PS5'],\n",
                "    'washer dryer': ['L2', 'L4', 'T1', 'P1', 'PS5', 'S2'],\n",
                "    'electric stove': ['L1', 'T2', 'P1', 'PS1', 'S1'],\n",
                "    'electric space heater': ['L4', 'T1', 'P2', 'PS1', 'S1'],\n",
                "}\n",
                "\n",
                "ALL_DEVICES = list(DEVICE_ATTRS.keys())\n",
                "\n",
                "print(f'ðŸ“‹ Attributes: {len(ATTR_IDS)}')\n",
                "print(f'ðŸ“‹ Devices: {len(ALL_DEVICES)}')\n",
                "for d, attrs in DEVICE_ATTRS.items():\n",
                "    print(f'   {d}: {attrs}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title âš¡ Model Definition\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "class HTFCNNEncoder(nn.Module):\n",
                "    def __init__(self, embed_dim=384):\n",
                "        super().__init__()\n",
                "        self.time_branch = nn.Sequential(\n",
                "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
                "            nn.Conv1d(64, 128, 5, padding=2), nn.BatchNorm1d(128), nn.ReLU(), nn.AdaptiveAvgPool1d(1)\n",
                "        )\n",
                "        self.freq_branch = nn.Sequential(\n",
                "            nn.Conv1d(1, 64, 3, padding=1), nn.BatchNorm1d(64), nn.ReLU(), nn.AdaptiveAvgPool1d(1)\n",
                "        )\n",
                "        self.fusion = nn.Sequential(\n",
                "            nn.Linear(128 + 64 + 6, 256), nn.LayerNorm(256), nn.ReLU(), nn.Dropout(0.2),\n",
                "            nn.Linear(256, embed_dim)\n",
                "        )\n",
                "    \n",
                "    def forward(self, signal, stats):\n",
                "        mean, std = signal.mean(1, keepdim=True), signal.std(1, keepdim=True) + 1e-6\n",
                "        norm = (signal - mean) / std\n",
                "        time_f = self.time_branch(norm.unsqueeze(1)).squeeze(-1)\n",
                "        fft = torch.abs(torch.fft.rfft(norm, dim=1))\n",
                "        fft = fft / (fft.max(1, keepdim=True)[0] + 1e-6)\n",
                "        freq_f = self.freq_branch(fft.unsqueeze(1)).squeeze(-1)\n",
                "        return self.fusion(torch.cat([time_f, freq_f, stats], dim=1))\n",
                "\n",
                "def compute_stats(s):\n",
                "    return np.array([np.mean(s), np.std(s), np.max(s)-np.min(s), np.max(s), np.min(s),\n",
                "                     np.max(np.abs(np.diff(s))) if len(s)>1 else 0], dtype=np.float32)\n",
                "\n",
                "print(f'âœ… Model: {sum(p.numel() for p in HTFCNNEncoder().parameters()):,} params')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ“Š Load Data with Attribute Labels\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "class AttributeDataset(Dataset):\n",
                "    def __init__(self, labels_file, ws=60, exclude_device=None):\n",
                "        self.samples = []\n",
                "        with open(labels_file) as f:\n",
                "            lines = f.readlines()\n",
                "        \n",
                "        for i in tqdm(range(0, len(lines)-ws, ws), desc='Loading'):\n",
                "            chunk = [json.loads(lines[j]) for j in range(i, i+ws)]\n",
                "            act = set(chunk[ws//2]['active_appliances']) & set(ALL_DEVICES)\n",
                "            if not act: continue\n",
                "            \n",
                "            # Skip if contains excluded device (LOO)\n",
                "            if exclude_device and exclude_device in act:\n",
                "                continue\n",
                "            \n",
                "            # Collect all attributes from active devices\n",
                "            attr_set = set()\n",
                "            for d in act:\n",
                "                attr_set.update(DEVICE_ATTRS.get(d, []))\n",
                "            \n",
                "            if not attr_set: continue\n",
                "            \n",
                "            signal = np.array([c['aggregate_power'] for c in chunk], dtype=np.float32)\n",
                "            \n",
                "            # Create attribute mask (multi-positive)\n",
                "            attr_mask = np.zeros(len(ATTR_IDS), dtype=np.float32)\n",
                "            for attr in attr_set:\n",
                "                attr_mask[ATTR_IDS.index(attr)] = 1.0\n",
                "            \n",
                "            self.samples.append({\n",
                "                'signal': signal,\n",
                "                'stats': compute_stats(signal),\n",
                "                'attr_mask': attr_mask,\n",
                "                'devices': list(act)\n",
                "            })\n",
                "        \n",
                "        print(f'ðŸ“Š Samples: {len(self.samples)}')\n",
                "    \n",
                "    def __len__(self): return len(self.samples)\n",
                "    def __getitem__(self, i):\n",
                "        s = self.samples[i]\n",
                "        return (torch.tensor(s['signal']), torch.tensor(s['stats']), \n",
                "                torch.tensor(s['attr_mask']))\n",
                "\n",
                "# Load full training data\n",
                "train_ds = AttributeDataset('combination_labels.jsonl')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ”¥ Multi-Positive Contrastive Training\n",
                "import torch.optim as optim\n",
                "\n",
                "def train_attribute_model(train_ds, epochs=EPOCHS):\n",
                "    print('=' * 60)\n",
                "    print('ðŸ”¥ Attribute-Level Training (Multi-Positive Contrastive)')\n",
                "    print('=' * 60)\n",
                "    \n",
                "    model = HTFCNNEncoder().to(DEVICE)\n",
                "    text_model = SentenceTransformer('all-MiniLM-L6-v2').to(DEVICE)\n",
                "    text_model.eval()\n",
                "    \n",
                "    # Encode attribute prototypes\n",
                "    with torch.no_grad():\n",
                "        attr_embs = text_model.encode(ATTR_TEXTS, convert_to_tensor=True, device=DEVICE)\n",
                "        attr_embs = F.normalize(attr_embs, p=2, dim=1)  # [K, 384]\n",
                "    \n",
                "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
                "    \n",
                "    def collate(batch):\n",
                "        signals = torch.stack([b[0] for b in batch])\n",
                "        stats = torch.stack([b[1] for b in batch])\n",
                "        masks = torch.stack([b[2] for b in batch])\n",
                "        return signals, stats, masks\n",
                "    \n",
                "    loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
                "                        drop_last=True, collate_fn=collate)\n",
                "    \n",
                "    history = []\n",
                "    \n",
                "    for ep in range(epochs):\n",
                "        model.train()\n",
                "        total_loss = 0\n",
                "        \n",
                "        for signals, stats, masks in tqdm(loader, desc=f'Ep {ep+1}/{epochs}', leave=False):\n",
                "            signals, stats, masks = signals.to(DEVICE), stats.to(DEVICE), masks.to(DEVICE)\n",
                "            \n",
                "            # Power embedding\n",
                "            pe = F.normalize(model(signals, stats), p=2, dim=1)  # [B, 384]\n",
                "            \n",
                "            # Similarity to all attributes\n",
                "            sim = (pe @ attr_embs.T) / TEMPERATURE  # [B, K]\n",
                "            \n",
                "            # Multi-positive loss\n",
                "            # Maximize similarity to positive attributes, minimize to negative\n",
                "            pos_mask = masks  # [B, K]\n",
                "            neg_mask = 1 - masks\n",
                "            \n",
                "            # For each sample: -log(sum(exp(pos)) / sum(exp(all)))\n",
                "            exp_sim = torch.exp(sim)\n",
                "            pos_sum = (exp_sim * pos_mask).sum(dim=1)\n",
                "            all_sum = exp_sim.sum(dim=1)\n",
                "            loss = -torch.log(pos_sum / (all_sum + 1e-8)).mean()\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "            optimizer.step()\n",
                "            total_loss += loss.item()\n",
                "        \n",
                "        avg_loss = total_loss / len(loader)\n",
                "        history.append(avg_loss)\n",
                "        \n",
                "        if (ep+1) % 5 == 0 or ep == 0:\n",
                "            print(f'Epoch {ep+1}/{epochs} | Loss: {avg_loss:.4f}')\n",
                "    \n",
                "    torch.save(model.state_dict(), 'attr_power_clip_vnext.pth')\n",
                "    print('âœ… Model saved: attr_power_clip_vnext.pth')\n",
                "    \n",
                "    return model, text_model, attr_embs, history\n",
                "\n",
                "model, text_model, attr_embs, history = train_attribute_model(train_ds)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ“ˆ Training Curve\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(range(1, len(history)+1), history, 'b-o', lw=2)\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Attribute-Level Contrastive Training')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.savefig('attr_training_curve.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸŽ¯ Inference: Attribute Activation + Device Reasoning\n",
                "\n",
                "def infer_device(model, text_model, attr_embs, signal, stats):\n",
                "    \"\"\"Power â†’ Attributes â†’ Device\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        signal_t = torch.tensor(signal).unsqueeze(0).to(DEVICE)\n",
                "        stats_t = torch.tensor(stats).unsqueeze(0).to(DEVICE)\n",
                "        \n",
                "        # Power embedding\n",
                "        pe = F.normalize(model(signal_t, stats_t), p=2, dim=1)\n",
                "        \n",
                "        # Attribute similarities\n",
                "        sim = (pe @ attr_embs.T).squeeze().cpu().numpy()  # [K]\n",
                "    \n",
                "    # Soft activation\n",
                "    activations = 1 / (1 + np.exp(-sim * 5))  # sigmoid with scaling\n",
                "    \n",
                "    # Device reasoning\n",
                "    device_scores = {}\n",
                "    for device, expected_attrs in DEVICE_ATTRS.items():\n",
                "        indices = [ATTR_IDS.index(a) for a in expected_attrs]\n",
                "        score = np.mean([activations[i] for i in indices])\n",
                "        device_scores[device] = score\n",
                "    \n",
                "    # Top attributes\n",
                "    top_attrs = [(ATTR_IDS[i], ATTRIBUTES[ATTR_IDS[i]]['name'], activations[i]) \n",
                "                 for i in np.argsort(-activations)[:5]]\n",
                "    \n",
                "    # Top devices\n",
                "    sorted_devices = sorted(device_scores.items(), key=lambda x: -x[1])\n",
                "    \n",
                "    return {\n",
                "        'activations': dict(zip(ATTR_IDS, activations)),\n",
                "        'top_attrs': top_attrs,\n",
                "        'device_scores': device_scores,\n",
                "        'sorted_devices': sorted_devices\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ“Š Evaluation: Attribute & Device Metrics\n",
                "\n",
                "def evaluate_model(model, text_model, attr_embs):\n",
                "    # Load test samples (use full dataset for now)\n",
                "    test_samples = []\n",
                "    ws = 60\n",
                "    with open('combination_labels.jsonl') as f:\n",
                "        lines = f.readlines()\n",
                "    \n",
                "    for i in range(0, min(10000, len(lines)-ws), ws):\n",
                "        chunk = [json.loads(lines[j]) for j in range(i, i+ws)]\n",
                "        act = set(chunk[ws//2]['active_appliances']) & set(ALL_DEVICES)\n",
                "        if len(act) != 1: continue  # Pure single device\n",
                "        \n",
                "        signal = np.array([c['aggregate_power'] for c in chunk], dtype=np.float32)\n",
                "        device = list(act)[0]\n",
                "        test_samples.append({'signal': signal, 'stats': compute_stats(signal), 'device': device})\n",
                "    \n",
                "    print(f'ðŸ“Š Test samples: {len(test_samples)}')\n",
                "    \n",
                "    # Evaluate\n",
                "    device_ranks = []\n",
                "    attr_results = {a: [] for a in ATTR_IDS}\n",
                "    \n",
                "    for sample in tqdm(test_samples, desc='Evaluating'):\n",
                "        result = infer_device(model, text_model, attr_embs, sample['signal'], sample['stats'])\n",
                "        gt_device = sample['device']\n",
                "        gt_attrs = set(DEVICE_ATTRS[gt_device])\n",
                "        \n",
                "        # Device rank\n",
                "        sorted_devs = [d[0] for d in result['sorted_devices']]\n",
                "        rank = sorted_devs.index(gt_device) + 1\n",
                "        device_ranks.append(rank)\n",
                "        \n",
                "        # Attribute correctness\n",
                "        for attr_id in ATTR_IDS:\n",
                "            is_positive = attr_id in gt_attrs\n",
                "            activation = result['activations'][attr_id]\n",
                "            attr_results[attr_id].append((is_positive, activation))\n",
                "    \n",
                "    # Device metrics\n",
                "    avg_rank = np.mean(device_ranks)\n",
                "    top1 = np.mean([r == 1 for r in device_ranks]) * 100\n",
                "    top3 = np.mean([r <= 3 for r in device_ranks]) * 100\n",
                "    \n",
                "    print('\\nðŸ“Š Device-Level Results:')\n",
                "    print(f'   Avg Rank: {avg_rank:.2f} / 6 (random = 3.5)')\n",
                "    print(f'   Top-1: {top1:.1f}% (random = 16.7%)')\n",
                "    print(f'   Top-3: {top3:.1f}% (random = 50%)')\n",
                "    \n",
                "    return {\n",
                "        'device_ranks': device_ranks,\n",
                "        'avg_rank': avg_rank,\n",
                "        'top1': top1,\n",
                "        'top3': top3,\n",
                "        'attr_results': attr_results\n",
                "    }\n",
                "\n",
                "eval_results = evaluate_model(model, text_model, attr_embs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ¤– LLM Explanation (Gemini)\n",
                "import google.generativeai as genai\n",
                "\n",
                "try:\n",
                "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
                "    genai.configure(api_key=GEMINI_API_KEY)\n",
                "    llm = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
                "    print('âœ… Gemini connected')\n",
                "except:\n",
                "    llm = None\n",
                "    print('âš ï¸ Gemini not configured')\n",
                "\n",
                "def llm_explain(result, gt_device=None):\n",
                "    top_attrs = result['top_attrs']\n",
                "    sorted_devs = result['sorted_devices'][:3]\n",
                "    \n",
                "    prompt = f\"\"\"ä½ æ˜¯ä¸€ä½é›»åŠ›ç³»çµ±å°ˆå®¶ã€‚æ ¹æ“šä»¥ä¸‹åŠŸçŽ‡ä¿¡è™Ÿçš„å±¬æ€§åˆ†æžï¼Œè§£é‡‹è¨­å‚™æŽ¨è«–çµæžœã€‚\n",
                "\n",
                "## æª¢æ¸¬åˆ°çš„å±¬æ€§\n",
                "{chr(10).join([f\"- {a[1]}: {a[2]:.2f}\" for a in top_attrs])}\n",
                "\n",
                "## è¨­å‚™æŽ¨è«–çµæžœ\n",
                "{chr(10).join([f\"{i+1}. {d[0]}: {d[1]:.2f}\" for i, d in enumerate(sorted_devs)])}\n",
                "\n",
                "{f'## å¯¦éš›è¨­å‚™: {gt_device}' if gt_device else ''}\n",
                "\n",
                "è«‹ç°¡è¦è§£é‡‹ï¼š\n",
                "1. ç‚ºä»€éº¼ Top-1 è¨­å‚™æœ€å¯èƒ½ï¼Ÿ\n",
                "2. é€™äº›å±¬æ€§å¦‚ä½•å°æ‡‰åˆ°è¨­å‚™çš„ç‰©ç†ç‰¹æ€§ï¼Ÿ\n",
                "\n",
                "è«‹ç”¨ç¹é«”ä¸­æ–‡å›žç­”ï¼Œ100å­—å…§ã€‚\"\"\"\n",
                "    \n",
                "    if llm:\n",
                "        try:\n",
                "            response = llm.generate_content(prompt)\n",
                "            return response.text\n",
                "        except Exception as e:\n",
                "            return f'Error: {e}'\n",
                "    else:\n",
                "        return 'ã€LLM æœªé…ç½®ã€‘'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ”¬ Demo: Single Sample Analysis\n",
                "\n",
                "# Pick a random test sample\n",
                "ws = 60\n",
                "with open('combination_labels.jsonl') as f:\n",
                "    lines = f.readlines()\n",
                "\n",
                "# Find a fridge sample\n",
                "for i in range(1000, len(lines)-ws, ws):\n",
                "    chunk = [json.loads(lines[j]) for j in range(i, i+ws)]\n",
                "    act = set(chunk[ws//2]['active_appliances']) & set(ALL_DEVICES)\n",
                "    if 'fridge' in act and len(act) == 1:\n",
                "        signal = np.array([c['aggregate_power'] for c in chunk], dtype=np.float32)\n",
                "        stats = compute_stats(signal)\n",
                "        break\n",
                "\n",
                "result = infer_device(model, text_model, attr_embs, signal, stats)\n",
                "\n",
                "print('ðŸ“Š Sample: Fridge')\n",
                "print(f'\\nðŸ” Top-5 Attributes:')\n",
                "for attr_id, name, score in result['top_attrs']:\n",
                "    print(f'   {attr_id} ({name}): {score:.3f}')\n",
                "\n",
                "print(f'\\nðŸ  Device Scores:')\n",
                "for device, score in result['sorted_devices']:\n",
                "    marker = 'âœ…' if device == 'fridge' else '  '\n",
                "    print(f'   {marker} {device}: {score:.3f}')\n",
                "\n",
                "print(f'\\nðŸ¤– LLM Explanation:')\n",
                "print(llm_explain(result, 'fridge'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ðŸ’¾ Save Results\n",
                "\n",
                "with open('vnext_attr_results.json', 'w') as f:\n",
                "    json.dump({\n",
                "        'experiment': 'Power-CLIP vNext Attribute-Level',\n",
                "        'epochs': EPOCHS,\n",
                "        'n_attributes': len(ATTR_IDS),\n",
                "        'device_metrics': {\n",
                "            'avg_rank': eval_results['avg_rank'],\n",
                "            'top1': eval_results['top1'],\n",
                "            'top3': eval_results['top3']\n",
                "        },\n",
                "        'loss_history': history\n",
                "    }, f, indent=2)\n",
                "\n",
                "from google.colab import files\n",
                "for fn in ['vnext_attr_results.json', 'attr_training_curve.png', 'attr_power_clip_vnext.pth']:\n",
                "    if os.path.exists(fn):\n",
                "        print(f'â¬‡ï¸ {fn}')\n",
                "        try: files.download(fn)\n",
                "        except: pass"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}